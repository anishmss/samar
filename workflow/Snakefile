from os import path
import itertools 
#configfile: "testdata/config_test.yaml"

if "fasta" in config:
    if config["fasta"].lower() != "no":
    	interleave = srcdir("scripts/fasta-interleave.sh")
    	file_type = "fasta"
    else:
    	interleave = srcdir("scripts/fastq-to-fasta-interleave.sh")
    	file_type = "fastq"
else:
    interleave = srcdir("scripts/fastq-to-fasta-interleave.sh")
    file_type = "fastq"

seq_count = srcdir("scripts/seq_count.py")
trans_6frame = srcdir("scripts/translate_6frames.py")
last_deseq2 = srcdir("scripts/last2deseq.R")

# Fix empty configs

#Input functions
def get_read1(wildcards):
    return config["reads"][wildcards.sample_id][0]

def get_read2(wildcards):
    return config["reads"][wildcards.sample_id][1]

def getMean(wildcard):
    est_path = "{}/last_alignments/{}.frag_len_est".format(config["out_dir"],wildcard)
    if(path.exists(est_path)):
	    with open(est_path) as f:
	    	for line in f:
	    		if line.startswith("# estimated mean distance"):
	    			return(line.rstrip().split()[-1])
    else:
    	return(-1)

def getSTD(wildcard):
    est_path = "{}/last_alignments/{}.frag_len_est".format(config["out_dir"],wildcard)
    if(path.exists(est_path)):
	    with open(est_path) as f:
	    	for line in f:
    			if line.startswith("# estimated standard deviation of distance"):
		    		return(line.rstrip().split()[-1])
    else:
    	return(-1)

def getScoring(wildcards):
    if "training" in config:
        if config["training"].lower() != "no":
            return config["out_dir"]+"score_sample/scoring_scheme"
        else: return "BL62"
    else:
        return "BL62"

def get_input_align_last(wildcards):
    input_dict = {}
    input_dict["reference_flag"] = config["out_dir"]+"last_index/index.done"
    input_dict["reads1"] = get_read1(wildcards)
    input_dict["reads2"] = get_read2(wildcards)
    #input_dict["frag_len_est"] = config["out_dir"]+"last_alignments/{sample_id}.frag_len_est"
    if "training" in config:
        if config["training"].lower() != "no":
            input_dict["scoring"] = config["out_dir"]+"score_sample/scoring_scheme"
    else:
        input_dict["scoring"] = config["out_dir"]+"score_sample/scoring_scheme"
    return input_dict
    
deseqOutput = [config["out_dir"]+'DEanalysis/DE_count_summary.txt',
	    	config["out_dir"]+'DEanalysis/DESeq2_fit.RDS'
	    	]

dynamicFiles = config["out_dir"]+'DEanalysis/Test_result-{}_{}_vs_{}.csv'

levels = list(dict(config["sample_info"]).values())
factorsxlevels = {}

for n,factor in enumerate(config["factors"]):
    factorsxlevels[factor] = []
    for level in levels:
    	if(level[n] not in factorsxlevels[factor]):
   	    factorsxlevels[factor].append(level[n])
   	        
for factor in config["design"].split(" + "):
    if("*" not in factor):
        for x in range(1,len(factorsxlevels[factor])):
            deseqOutput.append(dynamicFiles.format(factor,factorsxlevels[factor][x],factorsxlevels[factor][0]))    
 
for term in config["design"].split("+") :
    if("*" in term):
        interactionTerm = term.replace(" ", "").split("*")
        for order in range(1,len(interactionTerm)):
            for comb in list(itertools.combinations(interactionTerm, order + 1)):
                coeff = [list(map(lambda x: i+x, factorsxlevels[i][1:])) for i in comb]
                coeffTests = [config["out_dir"]+"DEanalysis/Test_result-" + '.'.join(i) + ".csv" for i in list(itertools.product(*coeff))]
                deseqOutput.extend(coeffTests)

all_input = deseqOutput
if "deanalysis" in config:
    if config["deanalysis"].lower() == "no":
        all_input = expand(config["out_dir"]+"counts/{sample_id}/{sample_id}.counts",sample_id=config["reads"].keys())

# Rule declarations begin here:
rule all: #Initial Rule in snakemake
    input: all_input

rule deseq: #Rule for performing Differential Expression Analysis
    input:
        [
            expand(config["out_dir"]+"counts/{sample_id}/{sample_id}.counts",sample_id=config["reads"].keys())
        ]
    output:
    	deseqOutput,
    params:
    	count_dir="{0}/counts".format(config["out_dir"]),
    	outdir = "{0}/DEanalysis".format(config["out_dir"]),
    	sample_info = str(dict(config["sample_info"])).replace("'","\""),
    	design = str(config["design"]),
    	factors = str(config["factors"]).replace("'","\""),
    conda:
    	"env/r.yaml"
    shell:
    	"Rscript {last_deseq2} --in_dir '{params.count_dir}' --factors '{params.factors}'"
    	" --design '{params.design}' --sample_info '{params.sample_info}' --out_dir '{params.outdir}'"

rule last_db: #Rule for constructing LAST index
    input:
        reference = config["reference_p"]
    output:
       touch(config["out_dir"]+'last_index/index.done')
    params:
       index_basename="{0}/last_index/index".format(config["out_dir"])
    conda:
    	"env/last.yaml"
    shell:
       "lastdb -p {params.index_basename} {input.reference}"
       #"lastdb {params.index_basename} {input.reference}"

rule last_score_training: #Rule for training score parameters
    input:
    	reference_flag = config["out_dir"]+"last_index/index.done",
	    query = config["reads"][list(config["reads"].keys())[0]][0],
    params:
        last_index_basename="{0}/last_index/index".format(config["out_dir"]),
        last_sample1="{0}/score_sample/sample_1.sample.fa".format(config["out_dir"]),
        last_trans_sample1="{0}/score_sample/translated.fasta".format(config["out_dir"]),
        file_type=file_type,
    output:
    	config["out_dir"]+"score_sample/scoring_scheme"
    conda:
    	"env/lastxpy.yaml"
    shell:
    	"""
    	head -n 400000 {input.query} > {params.last_sample1}
    	python {trans_6frame} {params.last_sample1} {params.file_type} {params.last_trans_sample1}
    	last-train --revsym --matsym --gapsym --sample-number=600000 -S0 {params.last_index_basename} {params.last_trans_sample1}> {output}
	    """

rule last_frag_stat_est: #Rule for estimating length distribution of paired-end reads
    input:
        unpack(get_input_align_last)
        #reference_flag = config["out_dir"]+"last_index/index.done",
        #reads1 = get_read1,
        #reads2 = get_read2,
        #scoring = config["out_dir"]+"last_sample/scoring_scheme",
    params:
        last_index_basename= config["out_dir"]+"/last_index/index",
        last_al = config["out_dir"]+"/last_alignments",
        scoring = getScoring
    output :
        frag_len_est=config["out_dir"]+"last_alignments/{sample_id}.frag_len_est",
    conda:
    	"env/last.yaml"
    shell:
        """
        mkfifo {params.last_al}/{wildcards.sample_id}_1
        mkfifo {params.last_al}/{wildcards.sample_id}_2
        gzip -cdf {input.reads1} | head -n 400000 > {params.last_al}/{wildcards.sample_id}_1 &
        gzip -cdf {input.reads2} | head -n 400000 > {params.last_al}/{wildcards.sample_id}_2 &
        {interleave} {params.last_al}/{wildcards.sample_id}_1 {params.last_al}/{wildcards.sample_id}_2 | lastal -i1 -p {params.scoring} -F15 {params.last_index_basename} | last-pair-probs -e > {output.frag_len_est}
        rm {params.last_al}/{wildcards.sample_id}_1 {params.last_al}/{wildcards.sample_id}_2
        """

rule align_last: #Rule for aligning RNA-seq reads to protein database
    input:
        unpack(get_input_align_last),
        frag_len_est = config["out_dir"]+"last_alignments/{sample_id}.frag_len_est"
    #    frag_len_est = config["out_dir"]+"last_alignments/{sample_id}.frag_len_est"
    #    reference_flag = config["out_dir"]+"last_index/index.done",
    #    reads1 = get_read1,
    #    reads2 = get_read2,
    #    frag_len_est= config["out_dir"]+"last_alignments/{sample_id}.frag_len_est",
    #    scoring = config["out_dir"]+"last_sample/scoring_scheme",
    params:
        last_index_basename="{0}/last_index/index".format(config["out_dir"]),
        mean = getMean,
        std = getSTD,
        #scoring = config["out_dir"]+"last_sample/scoring_scheme"
        scoring = getScoring
    threads: workflow.cores/len(config["reads"])
    output:
        config["out_dir"]+"last_alignments/{sample_id}.tab"
    conda:
    	"env/lastal.yaml"
    shell:
        "{interleave} {input.reads1} {input.reads2} | "
        "parallel --gnu --pipe -L4 -j {threads} 'lastal -i1 -p {params.scoring} -F20 {params.last_index_basename}' |"
        "last-pair-probs -f {params.mean} -s {params.std} -m 0.95 -d 0.1 |"
        "maf-convert tab > {output}"

rule count_last: #Rule for getting count data from LAST alignments
    input:
        alignments = config["out_dir"]+"last_alignments/{sample_id}.tab",
        reference = config["reference_p"]
    params:
    	mean = getMean,
    	std = getSTD,
    output:
        config["out_dir"]+"counts/{sample_id}/{sample_id}.counts"
    conda:
    	"env/counting.yaml"
    shell:
        "python {seq_count} {input.alignments} {output} --frag_len_mean {params.mean} --frag_len_std {params.std} --reference {input.reference}"
